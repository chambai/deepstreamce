{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-06 10:25:45.470654\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "model will be stored in models/vgg16_cifar10_2classes01.h5\n"
     ]
    }
   ],
   "source": [
    "#=========================================================================\n",
    "# Trains VGG16 DNN on 2 classes from CIFAR-10 dataset\n",
    "# and stores h5 model in models directory\n",
    "#=========================================================================\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "#=========================================================================\n",
    "def filterDataByClass(x_data, y_data, class_array):\n",
    "    ix = np.isin(y_data, class_array)\n",
    "    ixArry = np.where(ix)\n",
    "    indexes = ixArry[0] # list of indexes that have specified classes\n",
    "    x_data = x_data[indexes]\n",
    "    y_data = y_data[indexes]\n",
    "    return x_data, y_data\n",
    "\n",
    "#=========================================================================\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# set parameters-------------------------------\n",
    "# Only train and test on the specified classes\n",
    "classes = [0,1]\n",
    "baseModelName = 'vgg16'\n",
    "datasetName = 'cifar10'\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "#----------------------------------------------\n",
    "\n",
    "classesName = ''.join(str(x) for x in classes)\n",
    "num_classes = len(classes)\n",
    "\n",
    "model_name = baseModelName + '_' + datasetName + '_' + str(num_classes) + 'classes' + classesName + '.h5'\n",
    "modelLocation = 'models/%s'%(model_name)\n",
    "print('model will be stored in %s'%(modelLocation))\n",
    "x_train, y_train = filterDataByClass(x_train, y_train, classes)\n",
    "x_test, y_test = filterDataByClass(x_test, y_test, classes)\n",
    "\n",
    "# convert training data to zero's and 1's as 'to categorical' needs this\n",
    "i = 0;\n",
    "for c in classes:\n",
    "    y_train[y_train == c] = i\n",
    "    y_test[y_test == c] = i\n",
    "    i += 1;\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# model starts here--------------\n",
    "vggmodel = VGG16(\n",
    "    weights=None, \n",
    "    include_top=True, \n",
    "    classes=num_classes,\n",
    "    input_shape=(32,32,3)\n",
    ")\n",
    "\n",
    "vggmodel.summary()\n",
    "\n",
    "model = vggmodel\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)  # original\n",
    "\n",
    "# same optimiser as used in the paper\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='sgd',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "   model_name, \n",
    "   monitor='val_acc', \n",
    "   verbose=0, \n",
    "   save_best_only=True, \n",
    "   save_weights_only=False,\n",
    "   mode='auto')\n",
    "\n",
    "history = model.fit(\n",
    "   x=x_train,\n",
    "   y=y_train,\n",
    "   validation_split=0.1,\n",
    "   batch_size=batch_size,\n",
    "   epochs=epochs,\n",
    "   callbacks=[checkpoint],\n",
    "   verbose=1)\n",
    "\n",
    "# Save model and weights\n",
    "model.save(modelLocation)\n",
    "print('Saved trained model at %s ' %(modelLocation))\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n"
     ]
    }
   ],
   "source": [
    "classes = [0,1]\n",
    "classesName = ''.join(str(x) for x in classes)\n",
    "print(classesName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
